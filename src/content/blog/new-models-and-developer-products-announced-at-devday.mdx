---
authors: OpenAI
data: 2023年11月6日
---

# DevDay 上发布的新模型和开发人员产品

具有 128K 上下文和更低价格的 GPT-4 Turbo、新的助理 API、具有 Vision 的 GPT-4-Turbo、DALL·E 3 API 等。

今天，我们分享了数十项新的添加和改进，并在平台的许多部分降低了价格。其中包括：

- 新的 GPT-4 Turbo 型号功能更强、价格更低，支持 128K 上下文窗口
- 新的助手 API，使开发人员更容易构建自己的辅助人工智能应用程序，这些应用程序具有目标并可以调用模型和工具
- 平台中的新多模式功能，包括视觉、图像创建（DALL·E 3）和文本到语音（TTS）

我们将从今天下午 1 点开始向 OpenAI 客户推出新功能。

了解更多关于 ChatGPT 的 OpenAI DevDay 公告。

## 具有 128K 上下文的 GPT-4 Turbo

我们在 3 月份发布了 GPT-4 的第一个版本，并在 7 月份向所有开发人员提供了 GPT--4。今天，我们将推出下一代 GPT-4 Turbo 的预览版。

GPT-4 Turbo 的能力更强，并且对截至 2023 年 4 月的世界事件有了解。它有一个 128k 的上下文窗口，因此在一个提示中可以容纳相当于 300 多页文本的内容。我们还优化了其性能，因此与 GPT-4 相比，我们能够以 3 倍的输入代币价格和 2 倍的输出代币价格提供 GPT-4 Turbo。

GPT-4 Turbo 可供所有付费开发人员通过 API 中的 GPT-4-1106-preview 进行尝试，我们计划在未来几周内发布稳定的生产就绪模型。

## 函数调用更新

函数调用允许您向模型描述应用程序或外部 API 的函数，并让模型智能地选择输出包含参数的 JSON 对象来调用这些函数。我们今天发布了几项改进，包括在一条消息中调用多个功能的能力：用户可以发送一条消息请求多个操作，例如`打开车窗并关闭a/C`，这在以前需要与该模型进行多次往返（了解更多信息）。我们还在提高函数调用的准确性：GPT-4 Turbo 更有可能返回正确的函数参数。

## 改进了指令跟随和 JSON 模式

GPT-4 Turbo 在需要仔细遵循指令的任务上比我们以前的型号表现得更好，例如生成特定格式（例如，`始终以XML响应`）。它还支持我们新的 JSON 模式，确保模型将使用有效的 JSON 进行响应。新的 API 参数 response_format 使模型能够约束其输出，以生成语法正确的 JSON 对象。JSON 模式对于开发人员在函数调用之外的 Chat Complexions API 中生成 JSON 非常有用。

## 可再现输出和对数概率

新的种子参数通过使模型在大多数时间返回一致的完成，实现了可重复的输出。此测试版功能对于重放调试请求、编写更全面的单元测试以及通常对模型行为具有更高程度的控制等用例非常有用。我们 OpenAI 一直在内部使用这一功能进行我们自己的单元测试，并发现它非常宝贵。我们很高兴看到开发人员将如何使用它。了解更多信息。

我们还推出了一项功能，用于返回 GPT-4 Turbo 和 GPT-3.5 Turbo 在未来几周内生成的最有可能的输出令牌的日志概率，这将有助于构建搜索体验中的自动完成等功能。

## 更新的 GPT-3.5 Turbo

除了 GPT-4 Turbo，我们还发布了 GPT-3.5 Turbo 的新版本，默认情况下支持 16K 上下文窗口。新的 3.5 Turbo 支持改进的指令跟随、JSON 模式和并行函数调用。例如，我们的内部评估显示，在格式跟踪任务（如生成 JSON、XML 和 YAML）上有 38%的改进。开发人员可以通过在 API 中调用 gpt-3.5-turbo-1106 来访问这个新模型。使用 gpt-3.5-turbo 名称的应用程序将于 12 月 11 日自动升级为新型号。旧型号将继续通过 API 中的 gpt-3.5 涡轮-0613，直到 2024 年 6 月 13 日。了解更多信息。

## 助理 API、检索和代码解释器

今天，我们将发布 Assistants API，这是我们帮助开发人员在自己的应用程序中构建类似代理的体验的第一步。助手是一种专门构建的人工智能，它有特定的指令，利用额外的知识，并可以调用模型和工具来执行任务。新的助手 API 提供了新的功能，如代码解释器和检索以及函数调用，以处理您以前必须自己完成的大量繁重工作，并使您能够构建高质量的人工智能应用程序。

本 API 旨在实现灵活性；用例包括基于自然语言的数据分析应用程序、编码助手、人工智能度假计划器、语音控制 DJ、智能视觉 canvas 等等。助手 API 建立在启用我们新 GPT 产品的相同功能上：自定义指令和工具，如代码解释器、检索和函数调用。

这个 API 引入的一个关键变化是持久和无限长的线程，这允许开发人员将线程状态管理交给 OpenAI，并围绕上下文窗口约束进行工作。使用助理 API，您只需将每个新消息添加到现有线程中。

助理还可以根据需要调用新工具，包括：

- 代码解释器：在沙盒执行环境中编写和运行 Python 代码，可以生成图形和图表，并处理具有不同数据和格式的文件。它允许您的助手迭代运行代码，以解决具有挑战性的代码和数学问题，等等。
- 检索: 利用我们模型之外的知识增强助手，例如专有领域数据、产品信息或用户提供的文档。这意味着您不需要为文档计算和存储嵌入，也不需要实现分块和搜索算法。助理 API 根据我们在 ChatGPT 中构建知识检索的经验，优化了要使用的检索技术。
- 函数调用：使助手能够调用您定义的函数，并将函数响应包含在其消息中。
  与平台的其他部分一样，传递给 OpenAI API 的数据和文件永远不会用于训练我们的模型，开发人员可以在他们认为合适的时候删除数据。

您可以前往助理游乐场，在不编写任何代码的情况下尝试助理 API 测试版。

使用助理游乐场创建无代码的高质量助理。
助理 API 处于测试版，从今天开始所有开发人员都可以使用。请与我们（@OpenAI）分享您构建的内容，以及您的反馈，我们将在未来几周继续构建时纳入这些反馈。Assistants API 及其工具的定价可在我们的定价页面上获得。

## API 中的新模式

### 带视觉的 GPT-4 Turbo

GPT-4 Turbo 可以接受图像作为聊天完成 API 中的输入，从而实现生成字幕、详细分析真实世界图像以及阅读带数字的文档等用例。例如，BeMyEyes 使用这项技术帮助盲人或视力低下的人完成日常任务，如识别产品或浏览商店。开发人员可以通过在 API 中使用 gpt-4-vision-preview 来访问此功能。作为其稳定发布的一部分，我们计划向主要的 GPT-4 Turbo 型号推出视觉支持。定价取决于输入图像的大小。例如，将 1080×1080 像素的图像传递给 GPT-4 Turbo 需要 0.00765 美元。查看我们的视觉指南。

### DALL·E 3

开发人员可以通过我们的 Images API 将我们最近向 ChatGPT Plus 和企业用户推出的 DALL·E 3 直接集成到他们的应用程序和产品中，方法是将 DALL-E-3 指定为模型。Snap、可口可乐和 Shutterstock 等公司已使用 DALL·E 3 以编程方式为其客户和活动生成图像和设计。与 DALL·E 的前一版本类似，API 内置了审核功能，以帮助开发人员保护其应用程序免受滥用。我们提供不同的格式和质量选项，每张图像的起价为 0.04 美元。查看我们的 API DALL·E 3 入门指南。

### Text-to-speech (TTS)

开发人员现在可以通过文本到速度 API 从文本生成高质量的语音。我们的新 TTS 模型提供了六种预设语音可供选择，以及两种模型变体 TTS-1 和 TTS-1-hd。tts 针对实时用例进行了优化，tts-1-hd 针对质量进行了优化。价格从每输入 1000 个字符 0.015 美元起。查看我们的 TTS 指南即可开始。

### 收听语音样本

选择文本 Scenic

当金色的太阳落在地平线下，在宁静的草地上投下长长的阴影时，世界似乎安静了下来，一种平静的感觉笼罩着地球，预示着所有生命都将度过一个平静的夜晚。

选择语音

Alloy

## 模型自定义

### GPT-4 微调实验访问

我们正在创建一个用于 GPT-4 微调的实验访问程序。初步结果表明，与 GPT-3.5 微调实现的实质性增益相比，GPT-4 微调需要更多的工作来实现对基本模型的有意义的改进。随着 GPT-4 微调的质量和安全性的提高，积极使用 GPT-3.5 微调的开发人员将可以在其微调控制台中选择应用于 GPT-4 程序。

### 自定义模型

对于那些需要比微调更多定制的组织（特别适用于拥有超大专有数据集的领域——至少有数十亿个代币），我们还推出了一个自定义模型计划，让选定的组织有机会与一组专门的 OpenAI 研究人员合作，将自定义 GPT-4 训练到他们的特定领域。这包括修改模型训练过程的每一步，从进行额外的特定领域的预训练，到运行为特定领域量身定制的自定义 RL 后训练过程。组织将拥有对其自定义模型的独占访问权限。根据我们现有的企业隐私政策，自定义模型不会提供给其他客户或与其他客户共享，也不会用于培训其他模型。此外，提供给 OpenAI 以训练自定义模型的专有数据将不会在任何其他上下文中重复使用。这将是一个非常有限（且昂贵）的项目，感兴趣的组织可以在这里申请。

## 更低的价格和更高的费率限制

### 更低的价格

我们在整个平台上降低了几个价格，以将节省的费用转嫁给开发商（以下所有价格均以每 1000 个代币表示）：

- GPT-4 Turbo 输入代币比 GPT-4 便宜 3 倍，售价 0.01 美元，输出代币便宜 2 倍，售价 0.03 美元。
- GPT-3.5 Turbo 输入代币比之前的 16K 型号便宜 3 倍，售价 0.001 美元，输出代币便宜 2 倍，售价 0.002 美元。以前使用 GPT-3.5 Turbo 4K 的开发者可以从 0.001 美元的输入代币上获得 33%的折扣。这些较低的价格仅适用于今天推出的新款 GPT-3.5 Turbo。
- 微调后的 GPT-3.5 Turbo 4K 型号输入代币在 0.003 美元时减少了 4 倍，输出代币在 0.006 美元时便宜了 2.7 倍。微调还支持 16K 上下文，价格与新 GPT-3.5 Turbo 型号的 4K 相同。这些新价格也适用于微调的 gpt-3.5 涡轮-0613 型号。

|                           | 旧型号                                                                                                                                      | 新型号                                                                                               |
| ------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------- |
| GPT-4                     | Turbo GPT-4 8K<br /> Input: $0.03<br /> Output: $0.06<br /><br /> GPT-4 32K<br /> Input: $0.06<br /> Output: $0.12                          | GPT-4 Turbo 128K<br /> Input: $0.01<br /> Output: $0.03                                              |
| GPT-3.5 Turbo             | GPT-3.5 Turbo 4K <br /> Input: $0.0015 <br /> Output: $0.002 <br /> <br /> GPT-3.5 Turbo 16K <br />Input: $0.003<br /> Output: $0.004<br /> | GPT-3.5 Turbo 16K <br /> Input: $0.001<br /> Output: $0.002                                          |
| GPT-3.5 Turbo fine-tuning | GPT-3.5 Turbo 4K fine-tuning <br />Training: $0.008 <br />Input: $0.012 <br />Output: $0.016                                                | GPT-3.5 Turbo 4K and 16K fine-tuning <br />Training: $0.008 <br />Input: $0.003 <br />Output: $0.006 |

### 更高的费率限制

为了帮助您扩展应用程序，我们将所有付费 GPT-4 客户的每分钟代币限额提高一倍。您可以在费率限制页面中查看新的费率限制。我们还发布了确定自动费率限制增加的使用层，这样您就知道使用限制将如何自动扩展。您现在可以从帐户设置中请求增加使用限制。

## 版权保护

OpenAI 致力于通过我们系统中内置的版权保护来保护我们的客户。今天，我们将更进一步，推出版权保护——如果您面临侵犯版权的法律索赔，我们现在将介入并保护我们的客户，并支付由此产生的费用。这适用于 ChatGPT Enterprise 和我们的开发人员平台的通用功能。

## Whisper v3 和一致性解码器

我们将发布 [Whisper large v3](https://github.com/openai/whisper)，这是我们开源自动语音识别模型（ASR）的下一个版本，其特点是提高了跨语言的性能。我们还计划在不久的将来在我们的 API 中支持 Whisper v3。

我们还开源了[一致性解码器](https://github.com/openai/consistencydecoder)，这是稳定扩散 VAE 解码器的替代品。该解码器通过 Stable Diffusion 1.0+VAE 改进了所有兼容的图像，在文本、人脸和直线方面都有显著改进。

了解更多关于我们为 ChatGPT 发布的 OpenAI DevDay 公告。
